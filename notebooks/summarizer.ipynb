{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8ceee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "print(\" libraries loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503edaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your sample (or full Reviews.csv â€“ first 100 rows for speed)\n",
    "df = pd.read_csv('../data/Reviews.csv')  \n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst review:\")\n",
    "print(df['Text'].iloc[0])\n",
    "print(\"\\nFirst summary:\")\n",
    "print(df['Summary'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2900e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = df['Text'].iloc[0]  # Use first review\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "# Step 2: TF-IDF vectorizer (why? It scores important words)\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "\n",
    "# Step 3: Score sentences by similarity to whole text (cosine magic)\n",
    "scores = cosine_similarity(tfidf_matrix[-1:], tfidf_matrix)  # Last row = average\n",
    "scores = scores.flatten()\n",
    "\n",
    "# Step 4: Pick top 2 sentences (your summary!)\n",
    "top_indices = np.argsort(scores)[-2:]  # Top 2\n",
    "summary = [sentences[i] for i in top_indices]\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(text[:200] + \"...\")  # First 200 chars\n",
    "print(\"\\nTF-IDF Summary:\")\n",
    "print(' '.join(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5780ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try on second review\n",
    "text2 = df['Text'].iloc[1]\n",
    "sentences2 = sent_tokenize(text2)\n",
    "tfidf_matrix2 = vectorizer.fit_transform(sentences2)  # Re-fit for new text\n",
    "scores2 = cosine_similarity(tfidf_matrix2[-1:], tfidf_matrix2).flatten()\n",
    "top_indices2 = np.argsort(scores2)[-2:]\n",
    "summary2 = [sentences2[i] for i in top_indices2]\n",
    "\n",
    "print(\"Summary for review 2:\", ' '.join(summary2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
